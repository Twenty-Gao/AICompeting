#### 赛题数据级

- power_forecast_history.csv 为站点运营数据

- power.csv 为站点充电量数据

- stub_info.csv 为站点静态数据

- 训练集为历史一年的数据

- 测试集为未来一周的数据

  #### 评价指标

  ![1280X1280](%E7%AC%94%E8%AE%B01/1280X1280.PNG)

#### 解题思路：

本题任务是预测未来一周每天的需求电量，属于典型的回归问题，输入数据为历史站点运营数据、站点充电量数据和站点静态数据。针对这类时间序列预测问题方法比较灵活，传统的时序模型、机器学习、深度学习方法均可以使用。

1.统计策略：使用最近时刻的结果进行均值、中位数、时间衰减等方式直接统计得到未来结果，这种方式比较简单，可以快速得到结果。

2.时序模型：比较常用的方法有指数平滑法、灰色预测模型、ARIMA预测、季节Sarima模型、VAR模型等，仅能刻画序列信息，无法加入其他信息进行训练，比如离散类特征；

3.机器学习模型： 常见的有lightgbm、xgboost、catboost，需要构建大量时序相关特征；

4.深度学习模型：常见为rnn、lstm、cnn、transformer这类模型，可以直接输入序列信息，不需要构建大量的人工特征；

我们Baseline选择使用机器学习方法，在解决机器学习问题时，一般会遵循以下流程：（有不对的可以直接调整）

![img](%E7%AC%94%E8%AE%B01/whiteboard_exported_image%20(1).png)

- 决策树能够处理非线性关系，并且可以自动捕获特征之间的交互作用。
- 它可以生成可解释的规则，有助于理解模型如何做出决策。
- 决策树能够处理不同类型的特征，包括分类和数值型。

### 研读BaseLine代码

数据探索性分析，是通过了解数据集，了解变量间的相互关系以及变量与预测值之间的关系，对已有的数据在尽量少的先验假设下通过作图、制表、方程拟合、计算特征量等手段探索数据的结构和规律的一种数据分析方法，从而帮助我们后期更好的进行特征工程和建立模型，是机器学习中十分重要的一步。

#### 2.2数据清洗

数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。俗话说，	garbage in,garbage out.分析完数据后，特征工程前，必不可少的步骤就是对数据清洗。

数据清洗的作用是利用有关技术例如数理统计、数据挖掘或预定义的清理规则将脏数据转化为满足数据质量要求的数据。主要包括缺失值处理、异常值处理、数据分桶、特征归一化/标准化等流程。

特征工程指的是把原始数据转变为模型训练数据的过程，目的是获取更好的训练数据特征。特征工程能使得模型的性能得到提升，有时甚至在简单的模型上也能取得不错的效果。

#### 模型融合

进行模型融合的前提是有多个模型的输出结果，最常见的是将结果直接进行加权平均融合。

另外一种就是stacking融合，stacking是一种分层模型集成框架。以两层为例，第一层由多个基学习器组成，其输入为原始训练集，第二层的模型是以第一层基学习器的输出作为特征加入训练集进行再训练，从而得到完整的stacking模型。

**第一层：（类比cv_model函数）**

1. 划分训练数据为K折（5折为例，每次选择其中四份作为训练集，一份作为验证集）；
2. 针对各个模型RF、ET、GBDT、XGB，分别进行5次训练，每次训练保留一份样本用作训练时的验证，训练完成后分别对Validation set，Test set进行预测，对于Test set一个模型会对应5个预测结果，将这5个结果取平均；对于Validation set一个模型经过5次交叉验证后，所有验证集数据都含有一个标签。此步骤结束后：**5个验证集（总数相当于训练集全部）在每个模型下分别有一个预测标签，每行数据共有4个标签（4个算法模型），测试集每行数据也拥有四个标签（4个模型分别预测得到的）**

**第二层：（类比stack_model函数）**

1. 将训练集中的四个标签外加真实标签当作**五列新的特征作为新的训练集**，选取一个训练模型，根据新的训练集进行训练，然后应用**测试集的四个标签组成的测试集**进行预测作为最终的result。